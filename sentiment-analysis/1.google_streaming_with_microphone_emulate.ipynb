{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. 개발환경 설정하기\n",
    "\n",
    "+ [Google Cloud Speech-to-Text 개발환경 설정하기](https://github.com/sungalex/VoiceMagic/blob/master/google%20cloud%20speech-to-text%20%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0.pdf)\n",
    "+ [Google Cloud Speech-to-Text 참고자료](https://github.com/sungalex/VoiceMagic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. 파이썬 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade google-cloud-storage # 구글 클라우드 플랫폼에서 버킷으로 음성파일 분석할 때 필요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyaudio # (Window, Mac) 음성인식 기능 패키지 pyaudio 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (For Mac) pip install pyaudio 에러 발생 시 터미널 킨 후 아래와 같이 시도\n",
    "\n",
    "brew update  \n",
    "brew install portaudio  \n",
    "brew link --overwrite portaudio  \n",
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. 환경변수 설정\n",
    "+ 주피터 노트북에서 Google STT api를 실행하기 위해 json파일 환경변수 설정 필요함\n",
    "+ 구글 클라우드 플랫폼에서 비공개 json 파일을 다운받은 후, 아래 경로에 json파일 경로를 입력\n",
    "+ (For Mac) 파일 경로를 알기 힘들 경우, 터미널을 킨 후 파일을 터미널에 드래그하면 경로 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "    # 환경변수 설정\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/Users/hyunwoo/Desktop/speech-to-text-273518-4131322696e3.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/YOU-DB/Code/git/Capstone-Design/sentiment-analysis/capstone-275211-e60e60421509.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microphone Streaming emulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'transcript' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b8b28be3f1cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# __name__ : 현재 실행중인 모듈이름, 현재 실행 중인 모듈이 main모듈(프로그램 시작점)인지 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-b8b28be3f1cb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# Now, put the transcription responses to use.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mlisten_print_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m#sentiment = api_request(Converted_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b8b28be3f1cb>\u001b[0m in \u001b[0;36mlisten_print_loop\u001b[1;34m(responses)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeech_event_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moverwrite_chars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'here is final text: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'transcript' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from __future__ import division  \n",
    "    # __future__ 모듈은 파이썬 2버전과 3버전을 동시에 동작하도록 함. division은 python 3 스타일의 나누기 지원. \n",
    "\n",
    "import re  \n",
    "    # 정규 표현식을 지원하기 위한 re(regular expression)모듈\n",
    "import sys  \n",
    "    # 파이썬 인터프리터 제어\n",
    "import time\n",
    "\n",
    "# [IMPORTS the Google Cloud clinet library, 밑 세줄]\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "    # enmus는 오디오 인코딩 타입 목록(enumerations)들이 포함되어있는 모듈\n",
    "from google.cloud.speech import types\n",
    "    # types는 요청에 필요한 클래스(Ex. types.RecognitionAudio)들 포함\n",
    "    \n",
    "import pyaudio\n",
    "#import portaudio\n",
    "    # 사용자 음성 녹음을 위한 모듈\n",
    "from six.moves import queue\n",
    "    # six는 Python 2, Python3 코드가 호환되도록 함.\n",
    "    # (설명) Python 3 recognized the standard library and moved several functions to different modules. \n",
    "    # Six provides a consistent interface to them through the fake six.moves module.\n",
    "    # https://six.readthedocs.io/#module-six.moves 참조\n",
    "    # queue : queue모듈이며 큐, 우선순위큐, 스택을 제공.\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms, 버퍼는 1600\n",
    "\n",
    "class MicrophoneStream(object):\n",
    "    \"\"\"마이크 입력 클래스\"\"\"\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "    \n",
    "    # 객체를 초기화하는 special method\n",
    "    # self.속성 = 매개변수형태로 속성 초기화\n",
    "    def __init__(self, rate, chunk):  \n",
    "        self._rate = rate   \n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    # with구문 진입시점에 자동으로 호출되는 __enter__(special method임)\n",
    "    def __enter__(self):\n",
    "        # pyaudio 인터페이스 생성\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        \n",
    "        # 16비트, 모노로 마이크 열기\n",
    "        # _fill_buffer 함수가 callback 함수인데\n",
    "        # 실제 버퍼가 쌓이면 callback함수인 _fill_buffer 함수가 호출됨.\n",
    "        # 즉, 마이크 입력으로 버퍼가 쌓이면 콜백함수인 _fill_buffer 함수로 전달 받음\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # with 구문을 빠져나오기 직전에 호출되는 special method 즉, 클래스 종료 시 발생\n",
    "    # type, value, traceback은 with 문을 빠져나오기 전에 예외가 발생했을 때의 정보를 나타냄\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        # pyaudio 종료\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        \n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "        \n",
    "    # 마이크 버퍼(chunk=1600)가 쌓이면 호출 됨\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        # 마이크 입력을 큐(queue)에 넣고 리턴. self_buff는 __init__ 메서드에서 큐 인스턴스로 초기화 됨\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    # 제너레이터 함수\n",
    "    def generator(self):\n",
    "        # 클래스 종료될 때까지 무한 루프\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            \n",
    "            # 큐에 데이터를 기다리는 block 상태\n",
    "            # get(block=True, timeout=None) : 큐에서 항목을 제거하고 반환. block이 참이고 timeout이 None(기본값)이면,\n",
    "            # 항목이 사용가능할 때까지 필요하면 블럭(대기). timeout이 양수면, 최대 timeout초 동안 블럭하고 그 시간 내에 사용가능\n",
    "            # 한 항목이 없으면 Empty 예외 발생. block이 거짓일 때, 즉시 사용할 수 있는 항목이 있으면 반환하고, 그렇지 않으면 \n",
    "            # Empty 예외 발생\n",
    "            chunk = self._buff.get()\n",
    "            \n",
    "            # 데이터가 없으면 문제 있음\n",
    "            if chunk is None:\n",
    "                return\n",
    "            \n",
    "            # data에 마이크 입력 받기\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            # 추가로 받을 마이크 데이터가 있는지 체크\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    # 데이터 추가\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    # 큐에 데이터가 없으면 break\n",
    "                    break\n",
    "            \n",
    "            # 마이크 데이터 리턴\n",
    "            yield b''.join(data)\n",
    "\n",
    "def listen_print_loop(responses):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        if response.speech_event_type:\n",
    "            time.sleep(2)\n",
    "            text = transcript + overwrite_chars\n",
    "            print('here is final text: {}'.format(text))\n",
    "            return text\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        # Display the transcription of the top alternative.\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        overwrite_chars = ' ' * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + '\\r')  # \\r : 커서를 맨 앞으로 위치시키기\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            num_chars_printed = len(transcript)\n",
    "\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "            \n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r'\\b(끝내자|exit|quit)\\b', transcript, re.I):\n",
    "                print('Exiting..')\n",
    "                break\n",
    "\n",
    "            num_chars_printed = 0\n",
    "            \n",
    "def main():\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    # 변환 언어 'en-US' or 'ko-KR'\n",
    "    language_code = 'ko-KR'  # a BCP-47 language tag\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    \n",
    "    # 모듈의 메서드와 특성(Fields)는 아래 참조 \n",
    "    # https://cloud.google.com/speech-to-text/docs/reference/rpc/google.cloud.speech.v1#streamingrecognitionconfig\n",
    "    # RecognitionConfig provides imformation to the recognizer that specifes how to process the request.\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        enable_automatic_punctuation=True,  # (optional) 구두점 삽입 옵션\n",
    "        language_code=language_code)\n",
    "    \n",
    "    # Streaming information to the recognizer that specifes how to process the request.\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        single_utterance=True,  # (optional) utterance 감지 시 텍스트 변환 종료\n",
    "        interim_results=True)\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        \n",
    "        # StreamingRecognizeRequest : Top level message sent by the client for the StreamingRecognize method.\n",
    "        # Multiple StreamingRecognizeRequest messages are sent. \n",
    "        # 제너레이터 표현식으로 되어있음\n",
    "        requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                    for content in audio_generator)\n",
    "\n",
    "        # streaming_recognize에서 리턴값으로 음성 분석 결과(results)를 리턴한다\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Now, put the transcription responses to use.\n",
    "        listen_print_loop(responses)\n",
    "        \n",
    "        #sentiment = api_request(Converted_text)\n",
    "\n",
    "if __name__ == '__main__':  # __name__ : 현재 실행중인 모듈이름, 현재 실행 중인 모듈이 main모듈(프로그램 시작점)인지 확인\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Storage bucket으로 음성파일을 텍스트 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1\n",
    "from google.cloud.speech_v1p1beta1 import enums\n",
    "\n",
    "def sample_recognize(storage_uri):\n",
    "    \"\"\"\n",
    "    Performs synchronous speech recognition on an audio file\n",
    "\n",
    "    Args:\n",
    "        storage_uri URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]\n",
    "    \"\"\"\n",
    "    \n",
    "    client = speech_v1p1beta1.SpeechClient()\n",
    "\n",
    "    # storage_uri = 'gs://cloud-samples-data/speech/brooklyn_bridge.mp3'\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"ko-KR\"  # ko-KR, en-US\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 44100\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.MP3\n",
    "    config = {\n",
    "            \"language_code\": language_code,\n",
    "            \"sample_rate_hertz\": sample_rate_hertz,\n",
    "            \"encoding\": encoding,\n",
    "        }\n",
    "    audio = {\"uri\": storage_uri}\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    for result in response.results:\n",
    "        # First alternative is the most probable result\n",
    "        alternative = result.alternatives[0]\n",
    "        print(u\"Transcript: {}\".format(alternative.transcript))\n",
    "\n",
    "sample_recognize('gs://speechtotext_bucket01/test.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division  \n",
    "    # __future__ 모듈은 파이썬 2버전과 3버전을 동시에 동작하도록 함. division은 python 3 스타일의 나누기 지원. \n",
    "\n",
    "import re  \n",
    "    # 정규 표현식을 지원하기 위한 re(regular expression)모듈\n",
    "import sys  \n",
    "    # 파이썬 인터프리터 제어\n",
    "import time\n",
    "\n",
    "# [IMPORTS the Google Cloud clinet library, 밑 세줄]\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "    # enmus는 오디오 인코딩 타입 목록(enumerations)들이 포함되어있는 모듈\n",
    "from google.cloud.speech import types\n",
    "    # types는 요청에 필요한 클래스(Ex. types.RecognitionAudio)들 포함\n",
    "\n",
    "import portaudio\n",
    "import pyaudio\n",
    "    # 사용자 음성 녹음을 위한 모듈\n",
    "from six.moves import queue\n",
    "    # six는 Python 2, Python3 코드가 호환되도록 함.\n",
    "    # (설명) Python 3 recognized the standard library and moved several functions to different modules. \n",
    "    # Six provides a consistent interface to them through the fake six.moves module.\n",
    "    # https://six.readthedocs.io/#module-six.moves 참조\n",
    "    # queue : queue모듈이며 큐, 우선순위큐, 스택을 제공.\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms, 버퍼는 1600\n",
    "\n",
    "\n",
    "self= pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "print(p.get_default_input_device_info())\n",
    "numdevices = info.get('deviceCount')\n",
    "print(\"hello\",\"w\")\n",
    "for i in range(0, numdevices):\n",
    "           if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "               print (\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
